#!/usr/bin/env python3
"""
Haystack Service CLI
Development and testing tool for the Haystack/Elasticsearch service
"""

import click
import subprocess
import json
import os
import sys
import time
import requests
from pathlib import Path
from typing import Dict, List, Optional

# Service configuration
SERVICE_NAME = "haystack"
API_PORT = 8000
ES_PORT = 9200
API_URL = f"http://localhost:{API_PORT}"
ES_URL = f"http://localhost:{ES_PORT}"
INDEX_NAME = "legal-documents-rag"

# Color output helpers
class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'

def success(msg: str):
    click.echo(f"{Colors.GREEN}✓ {msg}{Colors.ENDC}")

def error(msg: str):
    click.echo(f"{Colors.RED}✗ {msg}{Colors.ENDC}", err=True)

def info(msg: str):
    click.echo(f"{Colors.BLUE}ℹ {msg}{Colors.ENDC}")

def warning(msg: str):
    click.echo(f"{Colors.YELLOW}⚠ {msg}{Colors.ENDC}")

def format_content(content: str, max_lines: int = 15, line_width: int = 80) -> str:
    """Format content for display with smart truncation"""
    # Clean up whitespace and HTML entities
    content = ' '.join(content.split())
    content = content.replace('&quot;', '"').replace('&amp;', '&')
    
    # Try to extract the most relevant section
    # Legal documents often have key information after certain markers
    key_sections = [
        # Court holdings and rulings
        ('held that', 100), ('holds that', 100),
        ('court found', 100), ('court ruled', 100),
        ('we hold', 100), ('we find', 100),
        ('conclusion', 80), ('accordingly', 80),
        ('therefore', 80), ('thus', 60),
        
        # Legal standards and tests
        ('standard', 70), ('test', 70),
        ('factors', 70), ('elements', 70),
        
        # Case specifics
        ('plaintiff', 50), ('defendant', 50),
        ('alleges', 60), ('claims', 60),
        ('infringement', 80), ('violation', 80),
        
        # Procedural markers
        ('issue', 70), ('question', 70),
        ('whether', 60),
    ]
    
    # Find the highest scoring section
    best_score = 0
    best_start = 0
    content_lower = content.lower()
    
    for term, score in key_sections:
        pos = content_lower.find(term)
        if pos != -1 and score > best_score:
            best_score = score
            # Start a bit before the term for context
            best_start = max(0, pos - 100)
    
    # Extract section if we found a good match
    if best_score > 0:
        # Find sentence boundaries
        start = best_start
        # Go back to start of sentence
        while start > 0 and content[start-1] not in '.!?':
            start -= 1
        
        # Extract roughly max_lines worth of content
        char_limit = line_width * max_lines
        end = min(len(content), start + char_limit)
        
        # Try to end at sentence boundary
        last_period = content.rfind('.', start, end)
        if last_period > start:
            end = last_period + 1
        
        extract = content[start:end].strip()
        
        # Add ellipsis if truncated
        if start > 0:
            extract = "[...] " + extract
        if end < len(content):
            extract = extract + " [...]"
            
        content = extract
    
    # If no key sections found or content is short, show beginning
    elif len(content) > line_width * max_lines:
        # Show first part and indicate truncation
        char_limit = line_width * (max_lines - 1)
        last_period = content.rfind('.', 0, char_limit)
        if last_period > char_limit * 0.7:  # If we can end at sentence
            content = content[:last_period + 1] + "\n\n[... document continues]"
        else:
            # Cut at word boundary
            last_space = content.rfind(' ', 0, char_limit)
            content = content[:last_space] + " [...]\n\n[... document continues]"
    
    # Word wrap the final content
    lines = []
    paragraphs = content.split('\n')
    
    for para in paragraphs:
        if not para.strip():
            lines.append('')
            continue
            
        words = para.split()
        current_line = ""
        for word in words:
            if len(current_line + word) + 1 > line_width:
                if current_line:
                    lines.append(current_line)
                current_line = word
            else:
                current_line = current_line + " " + word if current_line else word
        if current_line:
            lines.append(current_line)
    
    return '\n'.join(lines)

def extract_embedded_metadata(content: str) -> Optional[Dict]:
    """Extract metadata from content that appears to contain embedded dictionary/JSON data"""
    import ast
    import re
    
    # Try to find dictionary-like content
    # Look for patterns like 'key': 'value' or "key": "value"
    if not content:
        return None
    
    # Find the start of what looks like metadata
    # Usually starts with 'case_name' or similar fields
    metadata_fields = [
        'case_name', 'court', 'date_filed', 'docket_number', 'judge', 
        'nature_of_suit', 'cause', 'jurisdiction_type', 'pacer_case_id',
        'federal_dn_judge_initials_assigned', 'slug'
    ]
    
    # Find where the metadata starts
    start_pos = -1
    for field in metadata_fields:
        pattern = rf"['\"]?{field}['\"]?\s*:"
        match = re.search(pattern, content)
        if match and (start_pos == -1 or match.start() < start_pos):
            start_pos = match.start()
    
    if start_pos == -1:
        return None
    
    # Try to extract the dictionary-like content
    # Look for balanced braces or until the actual document content starts
    try:
        # Simple approach: extract key-value pairs
        metadata = {}
        
        # Common patterns in the data
        patterns = [
            (r"'case_name'\s*:\s*'([^']*)'", 'case_name'),
            (r"'case_name_full'\s*:\s*'([^']*)'", 'case_name_full'),
            (r"'slug'\s*:\s*'([^']*)'", 'slug'),
            (r"'docket_number'\s*:\s*'([^']*)'", 'docket_number'),
            (r"'federal_dn_judge_initials_assigned'\s*:\s*'([^']*)'", 'judge'),
            (r"'court'\s*:\s*(\d+)", 'court_id'),
            (r"'date_filed'\s*:\s*'([^']*)'", 'date_filed'),
            (r"'cause'\s*:\s*'([^']*)'", 'cause'),
            (r"'nature_of_suit'\s*:\s*'([^']*)'", 'nature_of_suit'),
            (r"'jury_demand'\s*:\s*'([^']*)'", 'jury_demand'),
            (r"'jurisdiction_type'\s*:\s*'([^']*)'", 'jurisdiction_type'),
            (r"'pacer_case_id'\s*:\s*'([^']*)'", 'pacer_case_id'),
        ]
        
        for pattern, key in patterns:
            match = re.search(pattern, content[start_pos:start_pos+2000])  # Look in first 2000 chars
            if match:
                value = match.group(1)
                if value and value != 'None':
                    metadata[key] = value
        
        # If case_name is empty but we have a slug, derive case name from slug
        if metadata.get('slug') and not metadata.get('case_name'):
            slug = metadata['slug']
            # Convert slug to case name: "smith-v-jones" -> "Smith v. Jones"
            case_name = slug.replace('-v-', ' v. ')
            case_name = ' '.join(word.capitalize() for word in case_name.split('-'))
            metadata['case_name'] = case_name
        
        return metadata if metadata else None
        
    except Exception:
        return None

def format_metadata(metadata: Dict, indent: str = "") -> None:
    """Format metadata in a clean table-like format with colored field labels"""
    if not metadata:
        return
    
    # Define field display names and order
    field_order = [
        ('case_name', 'Case'),
        ('case_name_full', 'Full Case Name'),
        ('court', 'Court'),
        ('court_id', 'Court ID'),
        ('judge', 'Judge'),
        ('date_filed', 'Date Filed'),
        ('date', 'Date'),
        ('docket_number', 'Docket Number'),
        ('pacer_case_id', 'PACER Case ID'),
        ('cause', 'Cause'),
        ('nature_of_suit', 'Nature of Suit'),
        ('jury_demand', 'Jury Demand'),
        ('jurisdiction_type', 'Jurisdiction Type'),
        ('slug', 'Slug'),
        ('document_id', 'Document ID'),
        ('type', 'Type'),
        ('topic', 'Topic'),
        ('subtopic', 'Subtopic'),
        ('jurisdiction', 'Jurisdiction'),
        ('citation', 'Citation'),
        ('landmark_case', 'Landmark Case'),
        ('regulation', 'Regulation'),
        ('enforcement', 'Enforcement'),
        ('constitutional_basis', 'Constitutional Basis'),
        ('statute', 'Statute'),
        ('scope', 'Scope'),
        ('framework', 'Framework'),
        ('source', 'Source'),
        ('recent_development', 'Recent Development'),
    ]
    
    # Calculate max label width for alignment
    max_label_width = 0
    for field, label in field_order:
        if field in metadata:
            max_label_width = max(max_label_width, len(label))
    
    # Also check for any fields not in our order
    other_fields = []
    for field in metadata:
        if field not in [f[0] for f in field_order]:
            display_name = field.replace('_', ' ').title()
            max_label_width = max(max_label_width, len(display_name))
            other_fields.append((field, display_name))
    
    # Add padding
    max_label_width += 2
    
    click.echo(f"\n{Colors.BOLD}Metadata:{Colors.ENDC}")
    
    # Display fields in order
    displayed_fields = set()
    for field, label in field_order:
        if field in metadata:
            value = metadata[field]
            displayed_fields.add(field)
            
            # Format special fields
            if field == 'document_id' and isinstance(value, str) and len(value) > 16:
                value = f"{value[:8]}...{value[-4:]}"
            elif field == 'date_filed' or field == 'date':
                # Keep date formatting as is
                pass
            elif isinstance(value, bool):
                value = "Yes" if value else "No"
            elif isinstance(value, list):
                if field == 'exceptions':
                    value = ", ".join(value)
                else:
                    value = ", ".join(str(v) for v in value)
            
            # Print with colored label
            label_str = f"{indent}{Colors.BLUE}{label}:{Colors.ENDC}"
            padding = " " * (max_label_width - len(label) - 1)
            click.echo(f"{label_str}{padding}{value}")
    
    # Display any remaining fields
    for field, display_name in other_fields:
        if field not in displayed_fields:
            value = metadata[field]
            
            # Format value
            if isinstance(value, bool):
                value = "Yes" if value else "No"
            elif isinstance(value, list):
                value = ", ".join(str(v) for v in value)
            elif isinstance(value, dict):
                # For nested dicts, just show as JSON
                value = json.dumps(value, indent=2)
            
            label_str = f"{indent}{Colors.YELLOW}{display_name}:{Colors.ENDC}"
            padding = " " * (max_label_width - len(display_name) - 1)
            click.echo(f"{label_str}{padding}{value}")

@click.group()
@click.version_option(version='1.0.0')
def cli():
    """Haystack service CLI for development and testing"""
    pass

# Service management
@cli.command()
@click.option('--build', is_flag=True, help='Build images before starting')
@click.option('--standalone', is_flag=True, help='Start in standalone mode (no PostgreSQL)')
def start(build: bool, standalone: bool):
    """Start Haystack and Elasticsearch services"""
    info("Starting Haystack services...")
    
    # Set environment for standalone mode
    env_vars = ""
    if standalone:
        env_vars = "HAYSTACK_MODE=standalone "
        info("Starting in standalone mode (no PostgreSQL integration)")
    
    # Build command
    cmd = f"{env_vars}docker-compose -f ../../docker-compose.yml -f ../docker-compose.haystack.yml up -d"
    if build:
        cmd += " --build"
    cmd += " elasticsearch haystack-service"
    
    # Execute from the right directory
    original_dir = os.getcwd()
    os.chdir(Path(__file__).parent)
    
    result = subprocess.run(cmd, shell=True)
    os.chdir(original_dir)
    
    if result.returncode == 0:
        success("Services started")
        info("Waiting for services to be healthy...")
        
        # Wait for health
        if wait_for_health():
            success("All services are healthy")
            info(f"Haystack API: {API_URL}")
            info(f"Elasticsearch: {ES_URL}")
        else:
            warning("Services started but health check failed")
    else:
        error("Failed to start services")

@cli.command()
def stop():
    """Stop Haystack and Elasticsearch services"""
    info("Stopping Haystack services...")
    
    original_dir = os.getcwd()
    os.chdir(Path(__file__).parent)
    
    cmd = "docker-compose -f ../../docker-compose.yml -f ../docker-compose.haystack.yml stop elasticsearch haystack-service"
    result = subprocess.run(cmd, shell=True)
    
    os.chdir(original_dir)
    
    if result.returncode == 0:
        success("Services stopped")
    else:
        error("Failed to stop services")

@cli.command()
def status():
    """Check service health status"""
    info("Checking Haystack service status...")
    
    # Check containers
    containers = ['elasticsearch-judicial', 'haystack-judicial']
    for container in containers:
        result = subprocess.run(
            f"docker ps --filter name={container} --format '{{{{.Status}}}}'",
            shell=True, capture_output=True, text=True
        )
        if result.stdout.strip():
            success(f"{container}: {result.stdout.strip()}")
        else:
            error(f"{container}: Not running")
    
    # Check API health
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        if response.status_code == 200:
            success("Haystack API is healthy")
            health_data = response.json()
            click.echo(json.dumps(health_data, indent=2))
        else:
            error(f"Haystack API returned {response.status_code}")
    except requests.exceptions.RequestException as e:
        error(f"Cannot reach Haystack API: {str(e)}")
    
    # Check Elasticsearch
    try:
        response = requests.get(f"{ES_URL}/_cluster/health", timeout=5)
        if response.status_code == 200:
            health = response.json()
            status_color = Colors.GREEN if health['status'] == 'green' else Colors.YELLOW
            click.echo(f"Elasticsearch cluster: {status_color}{health['status']}{Colors.ENDC}")
        else:
            error(f"Elasticsearch returned {response.status_code}")
    except requests.exceptions.RequestException as e:
        error(f"Cannot reach Elasticsearch: {str(e)}")

@cli.command()
@click.option('--follow', '-f', is_flag=True, help='Follow log output')
@click.option('--tail', '-n', default=100, help='Number of lines to show')
def logs(follow: bool, tail: int):
    """View service logs"""
    cmd = f"docker-compose -f ../../docker-compose.yml -f ../docker-compose.haystack.yml logs --tail={tail}"
    if follow:
        cmd += " -f"
    cmd += " elasticsearch haystack-service"
    
    original_dir = os.getcwd()
    os.chdir(Path(__file__).parent)
    subprocess.run(cmd, shell=True)
    os.chdir(original_dir)

# Data management
@cli.command()
@click.argument('source', type=click.Choice(['test', 'postgres', 'file']))
@click.option('--limit', default=100, help='Number of documents to load')
@click.option('--file', 'filepath', help='Path to JSON file (for file source)')
@click.option('--query', help='PostgreSQL query (for postgres source)')
def load(source: str, limit: int, filepath: Optional[str], query: Optional[str]):
    """Load data into Haystack"""
    info(f"Loading data from {source}...")
    
    documents = []
    
    if source == 'test':
        # Generate test documents
        documents = generate_test_documents(limit)
        info(f"Generated {len(documents)} test documents")
        
    elif source == 'postgres':
        # Load from PostgreSQL
        if not query:
            query = f"""
                SELECT id, plain_text, court_id, case_name, date_filed
                FROM court_data.opinions
                WHERE plain_text IS NOT NULL AND plain_text != ''
                LIMIT {limit}
            """
        
        try:
            import psycopg2
            conn = psycopg2.connect(
                host=os.getenv('POSTGRES_HOST', 'localhost'),
                database=os.getenv('POSTGRES_DB', 'n8n'),
                user=os.getenv('POSTGRES_USER', 'postgres'),
                password=os.getenv('POSTGRES_PASSWORD', 'password')
            )
            cur = conn.cursor()
            cur.execute(query)
            
            for row in cur.fetchall():
                documents.append({
                    "content": row[1],
                    "metadata": {
                        "document_id": str(row[0]),
                        "court": row[2] if len(row) > 2 else None,
                        "case_name": row[3] if len(row) > 3 else None,
                        "date_filed": row[4].isoformat() if len(row) > 4 and row[4] else None,
                        "source": "courtlistener"
                    }
                })
            conn.close()
            success(f"Loaded {len(documents)} documents from PostgreSQL")
        except Exception as e:
            error(f"Failed to load from PostgreSQL: {str(e)}")
            return
            
    elif source == 'file':
        if not filepath:
            error("Please provide --file parameter")
            return
        
        try:
            with open(filepath) as f:
                documents = json.load(f)
            success(f"Loaded {len(documents)} documents from {filepath}")
        except Exception as e:
            error(f"Failed to load file: {str(e)}")
            return
    
    # Ingest documents
    if documents:
        ingest_documents(documents)

@cli.command()
@click.confirmation_option(prompt='Are you sure you want to clear all documents?')
def clear():
    """Clear all documents from Elasticsearch"""
    info(f"Clearing all documents from {INDEX_NAME}...")
    
    try:
        response = requests.delete(f"{ES_URL}/{INDEX_NAME}")
        if response.status_code in [200, 404]:
            success("All documents cleared")
        else:
            error(f"Failed to clear: {response.status_code}")
    except requests.exceptions.RequestException as e:
        error(f"Failed to connect to Elasticsearch: {str(e)}")

@cli.command()
@click.argument('query_text')
@click.option('--type', 'search_type', 
              type=click.Choice(['hybrid', 'vector', 'bm25']), 
              default='hybrid',
              help='Search type')
@click.option('--limit', default=5, help='Number of results')
@click.option('--filter', 'filters', multiple=True, 
              help='Filters in key=value format')
@click.option('--full', is_flag=True, help='Show full content without truncation')
@click.option('--json', 'output_json', is_flag=True, help='Output as JSON')
def search(query_text: str, search_type: str, limit: int, filters: tuple, full: bool, output_json: bool):
    """Search documents"""
    info(f"Searching for: '{query_text}' (type: {search_type})")
    
    # Parse filters
    filter_dict = {}
    for f in filters:
        if '=' in f:
            key, value = f.split('=', 1)
            filter_dict[f"metadata.{key}"] = value
    
    # Build request
    request_data = {
        'query': query_text,
        'search_type': search_type,
        'top_k': limit
    }
    if filter_dict:
        request_data['filters'] = filter_dict
    
    try:
        response = requests.post(f"{API_URL}/search", json=request_data)
        if response.status_code == 200:
            results = response.json()
            
            # JSON output
            if output_json:
                click.echo(json.dumps(results, indent=2))
                return
            
            success(f"Found {results['total_results']} results")
            
            for i, result in enumerate(results['results'][:limit], 1):
                click.echo(f"\n{Colors.BOLD}{'='*80}{Colors.ENDC}")
                click.echo(f"{Colors.BOLD}Result {i} of {min(limit, results['total_results'])}{Colors.ENDC}")
                click.echo(f"{Colors.BOLD}Score:{Colors.ENDC} {result['score']:.4f}")
                
                # Display metadata if available
                if result.get('metadata'):
                    format_metadata(result['metadata'])
                else:
                    # Try to extract metadata from content if it appears to be embedded
                    content = result.get('content', '')
                    if content and (content.strip().startswith('{') or "'case_name'" in content):
                        extracted_meta = extract_embedded_metadata(content)
                        if extracted_meta:
                            format_metadata(extracted_meta)
                
                # Display formatted content
                click.echo(f"\n{Colors.BOLD}Content:{Colors.ENDC}")
                if full:
                    # Show full content with basic wrapping
                    content = result['content']
                    # Basic word wrapping
                    words = content.split()
                    lines = []
                    current_line = ""
                    for word in words:
                        if len(current_line + word) + 1 > 80:
                            lines.append(current_line)
                            current_line = word
                        else:
                            current_line = current_line + " " + word if current_line else word
                    if current_line:
                        lines.append(current_line)
                    click.echo('\n'.join(lines))
                else:
                    formatted_content = format_content(result['content'])
                    click.echo(formatted_content)
        else:
            error(f"Search failed: {response.status_code}")
    except requests.exceptions.RequestException as e:
        error(f"Failed to connect: {str(e)}")

@cli.command()
def console():
    """Start interactive Python console"""
    info("Starting interactive console...")
    
    # Check for elasticsearch module
    try:
        import elasticsearch
    except ImportError:
        error("The 'elasticsearch' module is not installed")
        info("Install it with: pip install elasticsearch")
        return
    
    console_script = """
import requests
import json
import os

try:
    from elasticsearch import Elasticsearch
    es = Elasticsearch(['localhost:9200'])
except ImportError:
    print("Warning: elasticsearch module not available")
    es = None
api_url = 'http://localhost:8000'

def search(query, search_type='hybrid', limit=5):
    '''Quick search function'''
    response = requests.post(
        f'{api_url}/search',
        json={'query': query, 'search_type': search_type, 'top_k': limit}
    )
    return response.json()

def ingest(documents):
    '''Quick ingest function'''
    response = requests.post(f'{api_url}/ingest', json=documents)
    return response.json()

def get_doc(doc_id):
    '''Get document by ID'''
    response = requests.get(f'{api_url}/get_document_with_context/{doc_id}')
    return response.json()

# Quick access to test data
test_docs = [
    {
        "content": "Sample legal document about contracts",
        "metadata": {"type": "contract", "jurisdiction": "federal"}
    },
    {
        "content": "Constitutional law precedent case",
        "metadata": {"type": "constitutional", "court": "supreme"}
    }
]

print("\\n{0}Haystack Development Console{1}".format('\\033[1m', '\\033[0m'))
print("\\nAvailable objects:")
if es:
    print("  es           - Elasticsearch client")
else:
    print("  es           - Not available (install elasticsearch module)")
print("  api_url      - Haystack API base URL")
print("  search()     - Quick search: search('query')")
print("  ingest()     - Quick ingest: ingest(documents)")
print("  get_doc()    - Get document: get_doc('doc-id')")
print("  test_docs    - Sample documents for testing")
print("\\nExample: results = search('legal precedent')")
print()
"""
    
    # Write temporary script
    import tempfile
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(console_script)
        temp_file = f.name
    
    # Start interactive Python
    subprocess.run([sys.executable, '-i', temp_file])
    
    # Clean up
    os.unlink(temp_file)

# Elasticsearch commands
@cli.group()
def es():
    """Direct Elasticsearch operations"""
    pass

@es.command()
def indices():
    """List all indices"""
    try:
        response = requests.get(f'{ES_URL}/_cat/indices?v')
        click.echo(response.text)
    except requests.exceptions.RequestException as e:
        error(f"Failed to connect: {str(e)}")

@es.command()
def stats():
    """Get index statistics"""
    try:
        response = requests.get(f'{ES_URL}/{INDEX_NAME}/_stats')
        if response.status_code == 200:
            stats = response.json()
            if '_all' in stats:
                total_docs = stats['_all']['primaries']['docs']['count']
                total_size = stats['_all']['primaries']['store']['size_in_bytes']
                
                info(f"Index: {INDEX_NAME}")
                click.echo(f"Documents: {total_docs:,}")
                click.echo(f"Size: {total_size / 1024 / 1024:.2f} MB")
            else:
                warning("Index does not exist yet")
        else:
            error(f"Failed to get stats: {response.status_code}")
    except requests.exceptions.RequestException as e:
        error(f"Failed to connect: {str(e)}")

@es.command()
@click.argument('query_dsl')
def query(query_dsl: str):
    """Execute raw Elasticsearch query"""
    try:
        query_json = json.loads(query_dsl)
        response = requests.post(
            f'{ES_URL}/{INDEX_NAME}/_search',
            json=query_json,
            headers={'Content-Type': 'application/json'}
        )
        if response.status_code == 200:
            click.echo(json.dumps(response.json(), indent=2))
        else:
            error(f"Query failed: {response.status_code}")
    except json.JSONDecodeError as e:
        error(f"Invalid JSON: {str(e)}")
    except requests.exceptions.RequestException as e:
        error(f"Failed to connect: {str(e)}")

# Development utilities
@cli.command()
def test():
    """Run quick functionality test"""
    info("Running Haystack functionality test...")
    
    # 1. Check health
    click.echo("\n1. Checking service health...")
    try:
        response = requests.get(f"{API_URL}/health")
        if response.status_code == 200:
            success("API is healthy")
        else:
            error("API health check failed")
            return
    except:
        error("Cannot connect to API")
        return
    
    # 2. Ingest test document
    click.echo("\n2. Testing document ingestion...")
    test_doc = [{
        "content": "Test document for Haystack CLI validation",
        "metadata": {"type": "test", "timestamp": time.time()}
    }]
    
    try:
        response = requests.post(f"{API_URL}/ingest", json=test_doc)
        if response.status_code == 200:
            result = response.json()
            doc_id = result['document_ids'][0]
            success(f"Ingested test document: {doc_id}")
        else:
            error("Ingestion failed")
            return
    except Exception as e:
        error(f"Ingestion error: {str(e)}")
        return
    
    # 3. Test search
    click.echo("\n3. Testing search...")
    try:
        response = requests.post(
            f"{API_URL}/search",
            json={"query": "Haystack CLI validation", "top_k": 1}
        )
        if response.status_code == 200:
            results = response.json()
            if results['total_results'] > 0:
                success("Search working correctly")
            else:
                warning("Search returned no results")
        else:
            error("Search failed")
    except Exception as e:
        error(f"Search error: {str(e)}")
    
    click.echo("\n" + "="*50)
    success("Basic functionality test completed")

# Helper functions
def wait_for_health(timeout: int = 60) -> bool:
    """Wait for services to be healthy"""
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        try:
            # Check Haystack API
            api_response = requests.get(f"{API_URL}/health", timeout=2)
            
            # Check Elasticsearch
            es_response = requests.get(f"{ES_URL}/_cluster/health", timeout=2)
            
            if api_response.status_code == 200 and es_response.status_code == 200:
                return True
        except:
            pass
        
        time.sleep(2)
    
    return False

def ingest_documents(documents: List[Dict]):
    """Helper to ingest documents"""
    batch_size = 100
    total = len(documents)
    
    for i in range(0, total, batch_size):
        batch = documents[i:i+batch_size]
        try:
            response = requests.post(f"{API_URL}/ingest", json=batch)
            if response.status_code == 200:
                result = response.json()
                success(f"Ingested batch {i//batch_size + 1}: {result['documents_processed']} documents")
            else:
                error(f"Failed batch {i//batch_size + 1}: {response.status_code}")
        except requests.exceptions.RequestException as e:
            error(f"Failed to ingest batch: {str(e)}")

def generate_test_documents(count: int) -> List[Dict]:
    """Generate test documents"""
    templates = [
        "Legal analysis of {topic} in {area} law context.",
        "Court ruling on {topic} establishes {area} precedent.",
        "The {area} implications of {topic} are significant.",
        "Recent {topic} developments affect {area} practice."
    ]
    
    topics = ["contracts", "torts", "IP", "privacy", "compliance"]
    areas = ["federal", "state", "international", "constitutional"]
    
    documents = []
    import random
    
    for i in range(count):
        template = random.choice(templates)
        topic = random.choice(topics)
        area = random.choice(areas)
        
        documents.append({
            "content": template.format(topic=topic, area=area),
            "metadata": {
                "doc_id": f"test-{i}",
                "type": "test",
                "topic": topic,
                "area": area
            }
        })
    
    return documents

if __name__ == '__main__':
    cli()