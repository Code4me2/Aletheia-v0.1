{
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "c188c31c-1c45-4118-9ece-5b6057ab5177",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -20,
        1120
      ],
      "id": "19799c6d-a4d5-4ca1-ad79-b09ccd2bf721",
      "name": "Webhook",
      "webhookId": "c188c31c-1c45-4118-9ece-5b6057ab5177"
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $json.output }}",
        "options": {
          "responseCode": 200
        }
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.2,
      "position": [
        940,
        1120
      ],
      "id": "ab7fd962-fc0e-4286-a09f-b872de9e0faa",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "jsCode": "// Post-HTTP Request Node - Enhanced with detailed logging\nconst inputData = items[0].json;\n\n// Log the full response received from DeepSeek\nconsole.log(\"RAW DEEPSEEK RESPONSE:\", JSON.stringify(inputData, null, 2).substring(0, 500) + \"...\");\n\ntry {\n  // Extract the thinking portion if it exists\n  const thinkingMatch = /\\<think\\>([\\s\\S]*?)\\<\\/think\\>/.exec(inputData.response);\n  const thinking = thinkingMatch ? thinkingMatch[1].trim() : \"\";\n  \n  // Log whether thinking tags were found\n  if (thinking) {\n    console.log(\"THINKING TAGS FOUND - EXTRACTED THINKING:\", thinking.substring(0, 100) + \"...\");\n  } else {\n    console.log(\"NO THINKING TAGS FOUND IN RESPONSE\");\n  }\n  \n  // Extract the main response without the thinking tags\n  const mainResponse = inputData.response.replace(/\\<think\\>[\\s\\S]*?\\<\\/think\\>/g, \"\").trim();\n  console.log(\"MAIN RESPONSE EXTRACTED:\", mainResponse.substring(0, 100) + \"...\");\n  \n  // Create a properly formatted response object\n  const result = {\n    success: true,\n    response: mainResponse,\n    thinking: thinking,\n    model: inputData.model || \"deepseek-r1:1.5b\"\n  };\n  \n  // Assign to items and log final output\n  items[0].json = result;\n  console.log(\"FINAL PROCESSED OUTPUT:\", JSON.stringify({\n    success: result.success,\n    responseLength: result.response.length,\n    thinkingLength: result.thinking.length,\n    model: result.model\n  }, null, 2));\n  \n} catch (error) {\n  // Log detailed error information\n  console.log(\"ERROR PROCESSING RESPONSE:\", error.message);\n  console.log(\"ERROR STACK:\", error.stack);\n  console.log(\"RESPONSE THAT CAUSED ERROR:\", typeof inputData.response, \n    inputData.response ? inputData.response.substring(0, 100) : \"undefined or null\");\n  \n  // Return a valid error response\n  items[0].json = {\n    success: false,\n    error: `Failed to process response: ${error.message}`\n  };\n  console.log(\"ERROR RESPONSE RETURNED\");\n}\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        720,
        1540
      ],
      "id": "84fe8300-d1a3-4dc8-b7fb-af37fb3b0ef5",
      "name": "Post Processing"
    },
    {
      "parameters": {
        "jsCode": "// Change this in your pre-HTTP request code node\nconst items = $input.all();\nlet userMessage = \"No message found\";\n\n// Process message as before\nif (items[0].json.body && items[0].json.body.message) {\n  userMessage = items[0].json.body.message;\n} else if (items[0].json.message) {\n  userMessage = items[0].json.message;\n}\n\nconsole.log(\"MESSAGE EXTRACTED:\", userMessage);\n\nreturn [\n  {\n    json: {\n      ollama_payload: {\n        model: \"deepseek-r1:1.5b\",\n        prompt: String(userMessage),\n        stream: true  // Changed from false to true!\n      }\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        140,
        1540
      ],
      "id": "214654ca-fcd6-47d9-a6f1-8f05914d0410",
      "name": "Query submission"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://host.docker.internal:11434/api/generate",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"deepseek-r1:1.5b\",\n  \"prompt\": \"{{$json.ollama_payload.prompt}}\",\n  \"stream\": false\n}",
        "options": {
          "batching": {
            "batch": {}
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        440,
        840
      ],
      "id": "156c0da7-bc2a-424f-ac8c-4256c37e7bb7",
      "name": "deepseek call"
    },
    {
      "parameters": {
        "operation": "chat",
        "message": "={{ $json.ollama_payload.prompt }}",
        "showThinking": true
      },
      "type": "CUSTOM.dsr1",
      "typeVersion": 1,
      "position": [
        460,
        1540
      ],
      "id": "6e0587c4-b244-496c-8ac4-b991fc7f7e00",
      "name": "DeepSeek R11"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.body.message }}",
        "hasOutputParser": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        360,
        1120
      ],
      "id": "a731a91a-15fd-4756-b525-729631c998e6",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        260,
        1320
      ],
      "id": "382f3de4-9358-41ec-b77d-ff8d63161311",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "m3SCzV9hT0vTLsJW",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "12345"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        380,
        1340
      ],
      "id": "75ca613c-f0c6-42bf-a2b0-b1b4733e51ff",
      "name": "Simple Memory"
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Post Processing": {
      "main": [
        []
      ]
    },
    "Query submission": {
      "main": [
        [
          {
            "node": "DeepSeek R11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "DeepSeek R11": {
      "main": [
        [
          {
            "node": "Post Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "b85105d192092490d47e1bb9094bd7d6d4fe52d877290d0b7cf754ae341fdd3a"
  }
}